{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce3a2b4",
   "metadata": {},
   "source": [
    "# combine header for pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5115c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0046b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vnf=f'bridge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d775e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_headers(input_file_path, output_file_path):\n",
    "    with open(input_file_path, newline='') as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        first_header = next(reader)\n",
    "        second_header = next(reader)\n",
    "        combined_header = [f\"{a}-{b}\" for a, b in zip(first_header, second_header)]\n",
    "\n",
    "        with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "            writer = csv.writer(output_csvfile)\n",
    "\n",
    "            # Write the new header\n",
    "            writer.writerow(combined_header)\n",
    "\n",
    "            # Write the rest of the lines\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"new_file：{output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccc08b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp-2\n",
      "new_file：..\\data\\random_input_rate\\exp-2\\bridge-pcm_new.csv\n",
      "exp-3\n",
      "new_file：..\\data\\random_input_rate\\exp-3\\bridge-pcm_new.csv\n",
      "exp-4\n",
      "new_file：..\\data\\random_input_rate\\exp-4\\bridge-pcm_new.csv\n",
      "exp-5\n",
      "new_file：..\\data\\random_input_rate\\exp-5\\bridge-pcm_new.csv\n",
      "exp-6\n",
      "new_file：..\\data\\random_input_rate\\exp-6\\bridge-pcm_new.csv\n",
      "exp-7\n",
      "new_file：..\\data\\random_input_rate\\exp-7\\bridge-pcm_new.csv\n",
      "exp-8\n",
      "new_file：..\\data\\random_input_rate\\exp-8\\bridge-pcm_new.csv\n",
      "exp-9\n",
      "new_file：..\\data\\random_input_rate\\exp-9\\bridge-pcm_new.csv\n",
      "exp-10\n",
      "new_file：..\\data\\random_input_rate\\exp-10\\bridge-pcm_new.csv\n",
      "exp-11\n",
      "new_file：..\\data\\random_input_rate\\exp-11\\bridge-pcm_new.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,12):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\bridge-pcm.csv'\n",
    "    output_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\bridge-pcm_new.csv'\n",
    "    combine_csv_headers(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ecffa",
   "metadata": {},
   "source": [
    "# pcie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89bc256f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_ls=f'exp-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3c73aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: ..\\data\\random_input_rate\\exp-2\\pcm-pcie_new.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def reshape_and_remove_columns(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Extract and modify the header\n",
    "    original_header = rows[0]\n",
    "    new_header = [f'skt-0_{h}' for h in original_header] + [f'skt-1_{h}' for h in original_header]\n",
    "\n",
    "    # Process the data rows\n",
    "    reshaped_rows = []\n",
    "    for i in range(1, len(rows), 3):  # Skip every third row (the repeated header)\n",
    "        row_0 = rows[i]\n",
    "        if i + 1 < len(rows):  # Check if the next row exists\n",
    "            row_1 = rows[i+1]\n",
    "            combined_row = row_0 + row_1\n",
    "            reshaped_rows.append(combined_row)\n",
    "\n",
    "    # Remove columns: Find the index of the columns to be removed\n",
    "    indices_to_remove = [new_header.index('skt-0_Skt'), new_header.index('skt-1_Skt')]\n",
    "\n",
    "    # Remove columns: Remove the specified columns from the header and rows\n",
    "    updated_header = [h for i, h in enumerate(new_header) if i not in indices_to_remove]\n",
    "    updated_rows = [[item for i, item in enumerate(row) if i not in indices_to_remove] for row in reshaped_rows]\n",
    "\n",
    "    # Write the processed data to the output file\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(updated_header) \n",
    "        writer.writerows(updated_rows) \n",
    "    return output_file\n",
    "\n",
    "# Predefined file paths\n",
    "input_file = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-pcie.csv'\n",
    "output_file = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-pcie_new.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = reshape_and_remove_columns(input_file, output_file)\n",
    "print(f\"Processed file saved as: {result_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a35a852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp-2\n",
      "exp-3\n",
      "exp-4\n",
      "exp-5\n",
      "exp-6\n",
      "exp-7\n",
      "exp-8\n",
      "exp-9\n",
      "exp-10\n",
      "exp-11\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,12):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file= f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-pcie.csv'\n",
    "    output_file = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-pcie_new.csv'\n",
    "    processed_file = reshape_and_remove_columns(input_file, output_file)\n",
    "   # updated_file = remove_specific_columns(f'..\\\\data\\\\fixed_rate\\\\{exp_ls}\\\\pcm-pcie_new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d937ad",
   "metadata": {},
   "source": [
    "# memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea52aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def remove_columns_and_empty_values(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(\"CSV file is empty\")\n",
    "\n",
    "    # Find the index of the columns to be removed\n",
    "    header = rows[0]\n",
    "    num_columns = len(header)\n",
    "    indices_to_remove = [i for i, h in enumerate(header) if h.lower() in ['-date', '-time'] or all((len(row) > i and row[i] == '') for row in rows[1:])]\n",
    "\n",
    "    # Remove the specified columns from the header and rows\n",
    "    updated_header = [h for i, h in enumerate(header) if i not in indices_to_remove]\n",
    "    updated_rows = [[item for i, item in enumerate(row[:num_columns]) if i not in indices_to_remove] for row in rows[1:]]\n",
    "\n",
    "    # Write the updated data to the output file\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(updated_header)  \n",
    "        writer.writerows(updated_rows)  \n",
    "\n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef704a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp-2\n",
      "exp-3\n",
      "exp-4\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,5):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory.csv'\n",
    "    output_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory_new.csv'\n",
    "    remove_columns_and_empty_values(input_file_path, output_file_path)\n",
    "for i in range(6,11):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory.csv'\n",
    "    output_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory_new.csv'\n",
    "    remove_columns_and_empty_values(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93a447d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_headers(input_file_path, output_file_path):\n",
    "    with open(input_file_path, newline='') as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        first_header = next(reader)\n",
    "        second_header = next(reader)\n",
    "        combined_header = [f\"{a}-{b}\" for a, b in zip(first_header, second_header)]\n",
    "\n",
    "        with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "            writer = csv.writer(output_csvfile)\n",
    "\n",
    "            # Write the new header\n",
    "            writer.writerow(combined_header)\n",
    "\n",
    "            # Write the rest of the lines\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"new_file：{output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "567cd8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp-2\n",
      "new_file：..\\data\\random_input_rate\\exp-2\\pcm-memory_new.csv\n",
      "exp-3\n",
      "new_file：..\\data\\random_input_rate\\exp-3\\pcm-memory_new.csv\n",
      "exp-4\n",
      "new_file：..\\data\\random_input_rate\\exp-4\\pcm-memory_new.csv\n",
      "exp-6\n",
      "new_file：..\\data\\random_input_rate\\exp-6\\pcm-memory_new.csv\n",
      "exp-7\n",
      "new_file：..\\data\\random_input_rate\\exp-7\\pcm-memory_new.csv\n",
      "exp-8\n",
      "new_file：..\\data\\random_input_rate\\exp-8\\pcm-memory_new.csv\n",
      "exp-9\n",
      "new_file：..\\data\\random_input_rate\\exp-9\\pcm-memory_new.csv\n",
      "exp-10\n",
      "new_file：..\\data\\random_input_rate\\exp-10\\pcm-memory_new.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,5):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory.csv'\n",
    "    output_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory_new.csv'\n",
    "    combine_csv_headers(input_file_path, output_file_path)\n",
    "for i in range(6,11):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory.csv'\n",
    "    output_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\pcm-memory_new.csv'\n",
    "    combine_csv_headers(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d787db7",
   "metadata": {},
   "source": [
    "# latency preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe1c2d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def latency_pre(input_csv, output_csv, delimiter=' '):\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv, delimiter=delimiter, header=None)\n",
    "    df.drop(columns=df.columns[0], inplace=True)\n",
    "    df.to_csv(output_csv, index=False, header=False, sep=delimiter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83245141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp-1\n",
      "exp-2\n",
      "exp-3\n",
      "exp-4\n",
      "exp-5\n",
      "exp-6\n",
      "exp-7\n",
      "exp-8\n",
      "exp-9\n",
      "exp-10\n",
      "exp-11\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,12):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\latency.csv'\n",
    "    output_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\latency_new.csv'\n",
    "    latency_pre(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7b8c5",
   "metadata": {},
   "source": [
    "# add header for nf_out csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31e2833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def add_header_to_csv(input_file_path, output_file_path, header):\n",
    "    with open(input_file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "        \n",
    "    with open(output_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bad436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp-4\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n",
      "exp-5\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n",
      "exp-6\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n",
      "exp-7\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n",
      "exp-8\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n",
      "exp-9\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n",
      "exp-10\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n"
     ]
    }
   ],
   "source": [
    "for i in range(4,11):\n",
    "    exp_ls = f'exp-{i}'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\nf_out.csv'\n",
    "    output_file_path = f'..\\\\data\\\\random_input_rate\\\\{exp_ls}\\\\nf_out_new.csv'\n",
    "\n",
    "    header = [\"tag\", \"instance_id\", \"service_id\", \"thread_info.core\",\n",
    "              \"rx_pps\",\"tx_pps\", \"rx\", \"tx\", \"act_out\", \"act_tonf\",\"act_drop\", \"thread_info.parent\",\n",
    "              \"state\", \"rte_atomic16_read(thread_info.children_cnt)\", \n",
    "             \"rx_drop_rate\",\"tx_drop_rate\", \"rx_drop\",\"tx_drop\", \"act_next\", \n",
    "             \"act_buffer\",\"act_returned\"]\n",
    "    print(header)\n",
    "    add_header_to_csv( input_file_path, output_file_path, header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee85be1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def replace_header_in_csv(input_file_path, output_file_path, new_header):\n",
    "    with open(input_file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "\n",
    "    data[0] = new_header\n",
    "\n",
    "    with open(output_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(data)\n",
    "\n",
    "new_header = [\"tag\", \"instance_id\", \"service_id\", \"thread_info.core\",\n",
    "                  \"rx_pps\",\"tx_pps\", \"rx\", \"tx\", \"act_out\", \"act_tonf\",\"act_drop\", \"thread_info.parent\",\n",
    "                  \"state\", \"rte_atomic16_read(thread_info.children_cnt)\", \n",
    "                 \"rx_drop_rate\",\"tx_drop_rate\", \"rx_drop\",\"tx_drop\", \"act_next\", \n",
    "                 \"act_buffer\",\"act_returned\"]\n",
    "#replace_header_in_csv('path_to_input_file.csv', 'path_to_output_file.csv', new_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1019cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64B-256\n",
      "64B-512\n",
      "64B-1024\n",
      "64B-4096\n",
      "128B-256\n",
      "128B-512\n",
      "128B-1024\n",
      "128B-4096\n",
      "256B-256\n",
      "256B-512\n",
      "256B-1024\n",
      "256B-4096\n",
      "512B-256\n",
      "512B-512\n",
      "512B-1024\n",
      "512B-4096\n",
      "1510B-256\n",
      "1510B-512\n",
      "1510B-1024\n",
      "1510B-4096\n"
     ]
    }
   ],
   "source": [
    "for i in [64,128,256,512,1510]:\n",
    "    for j in [256,512,1024,4096]:\n",
    "        exp_ls = f'{i}B-{j}'\n",
    "        print(exp_ls)\n",
    "        input_file_path = f'..\\\\data\\\\fixed_rate\\\\{exp_ls}\\\\nf_out.csv'\n",
    "        output_file_path = f'..\\\\data\\\\fixed_rate\\\\{exp_ls}\\\\nf_out_new.csv'\n",
    "      \n",
    "        new_header = [\"tag\", \"instance_id\", \"service_id\", \"thread_info.core\",\n",
    "                  \"rx_pps\",\"tx_pps\", \"rx\", \"tx\", \"act_out\", \"act_tonf\",\"act_drop\", \"thread_info.parent\",\n",
    "                  \"state\", \"rte_atomic16_read(thread_info.children_cnt)\", \n",
    "                 \"rx_drop_rate\",\"tx_drop_rate\", \"rx_drop\",\"tx_drop\", \"act_next\", \n",
    "                 \"act_buffer\",\"act_returned\"]\n",
    "        replace_header_in_csv(input_file_path, output_file_path, new_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dd2772",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
