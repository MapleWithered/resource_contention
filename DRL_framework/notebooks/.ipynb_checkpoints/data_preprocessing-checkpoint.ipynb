{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dce3a2b4",
   "metadata": {},
   "source": [
    "# combine header for pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5115c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b667caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "vnf=f'ndpi_stats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d775e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_headers(input_file_path, output_file_path):\n",
    "    with open(input_file_path, newline='') as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        first_header = next(reader)\n",
    "        second_header = next(reader)\n",
    "        combined_header = [f\"{a}-{b}\" for a, b in zip(first_header, second_header)]\n",
    "\n",
    "        with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "            writer = csv.writer(output_csvfile)\n",
    "\n",
    "            # Write the new header\n",
    "            writer.writerow(combined_header)\n",
    "\n",
    "            # Write the rest of the lines\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"new_file：{output_file_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc08b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200s\n",
      "new_file：..\\ndpi-stats-random\\200s\\ndpi_stats-pcm_new.csv\n",
      "2000s\n",
      "new_file：..\\ndpi-stats-random\\2000s\\ndpi_stats-pcm_new.csv\n"
     ]
    }
   ],
   "source": [
    "for i in [200,2000]:\n",
    "    exp_ls = f'{i}s'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\{vnf}-pcm.csv'\n",
    "    output_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\{vnf}-pcm_new.csv'\n",
    "    combine_csv_headers(input_file_path, output_file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3ecffa",
   "metadata": {},
   "source": [
    "# pcie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53d43d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000s\n"
     ]
    }
   ],
   "source": [
    "print(exp_ls)\n",
    "exp_ls=\"200s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "61121f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed file saved as: ..\\ndpi-stats-random\\200s\\pcm-pcie_new.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def reshape_and_remove_columns(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    # Extract and modify the header\n",
    "    original_header = rows[0]\n",
    "    new_header = [f'skt-0_{h}-total' for h in original_header]+ [f'skt-0_{h}-miss' for h in original_header] + [f'skt-0_{h}-hit' for h in original_header]+[f'skt-1_{h}-total' for h in original_header]+ [f'skt-1_{h}-miss' for h in original_header]+ [f'skt-1_{h}-hit' for h in original_header]\n",
    "\n",
    "    # Process the data rows\n",
    "    reshaped_rows = []\n",
    "    for i in range(1, len(rows), 7):  # Skip every third row (the repeated header)\n",
    "        row_0 = rows[i]\n",
    "        if i + 1 < len(rows):  # Check if the next row exists\n",
    "            row_1 = rows[i+1]\n",
    "            row_2 = rows[i+2]\n",
    "            row_3 = rows[i+3]\n",
    "            row_4 = rows[i+4]\n",
    "            row_5 = rows[i+5]\n",
    "            combined_row = row_0 + row_1 + row_2 + row_3 + row_4 + row_5\n",
    "            reshaped_rows.append(combined_row)\n",
    "\n",
    "    # Remove columns: Find the index of the columns to be removed\n",
    "    indices_to_remove = [new_header.index('skt-0_Skt-total'), new_header.index('skt-1_Skt-total'),\n",
    "                        new_header.index('skt-0_Skt-miss'), new_header.index('skt-1_Skt-miss'),\n",
    "                        new_header.index('skt-0_Skt-hit'), new_header.index('skt-1_Skt-hit'),]\n",
    "\n",
    "    # Remove columns: Remove the specified columns from the header and rows\n",
    "    updated_header = [h for i, h in enumerate(new_header) if i not in indices_to_remove]\n",
    "    updated_rows = [[item for i, item in enumerate(row) if i not in indices_to_remove] for row in reshaped_rows]\n",
    "\n",
    "    # Write the processed data to the output file\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(updated_header) \n",
    "        writer.writerows(updated_rows) \n",
    "    return output_file\n",
    "\n",
    "# Predefined file paths\n",
    "input_file = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-pcie.csv'\n",
    "output_file =f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-pcie_new.csv'\n",
    "\n",
    "# Example usage\n",
    "result_file = reshape_and_remove_columns(input_file, output_file)\n",
    "print(f\"Processed file saved as: {result_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb2a2889",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-pcie.csv'\n",
    "output_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-pcie_new.csv'\n",
    "processed_file = process_csv(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9a35a852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200s\n",
      "2000s\n"
     ]
    }
   ],
   "source": [
    "for i in [200,2000]:\n",
    "    exp_ls = f'{i}s'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-pcie.csv'\n",
    "    output_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-pcie_new.csv'\n",
    "    processed_file = process_csv(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d937ad",
   "metadata": {},
   "source": [
    "# memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93a447d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_csv_headers(input_file_path, output_file_path):\n",
    "    with open(input_file_path, newline='') as input_csvfile:\n",
    "        reader = csv.reader(input_csvfile)\n",
    "        first_header = next(reader)\n",
    "        second_header = next(reader)\n",
    "        combined_header = [f\"{a}-{b}\" for a, b in zip(first_header, second_header)]\n",
    "\n",
    "        with open(output_file_path, 'w', newline='') as output_csvfile:\n",
    "            writer = csv.writer(output_csvfile)\n",
    "\n",
    "            # Write the new header\n",
    "            writer.writerow(combined_header)\n",
    "\n",
    "            # Write the rest of the lines\n",
    "            for row in reader:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    print(f\"new_file：{output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e57a13eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200s\n",
      "new_file：..\\ndpi-stats-random\\200s\\pcm-memory_new.csv\n",
      "2000s\n",
      "new_file：..\\ndpi-stats-random\\2000s\\pcm-memory_new.csv\n"
     ]
    }
   ],
   "source": [
    "for i in [200,2000]:\n",
    "    exp_ls = f'{i}s'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-memory.csv'\n",
    "    output_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-memory_new.csv'\n",
    "    combine_csv_headers(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea52aca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def remove_columns_and_empty_values(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        rows = list(reader)\n",
    "\n",
    "    if not rows:\n",
    "        raise ValueError(\"CSV file is empty\")\n",
    "\n",
    "    # Find the index of the columns to be removed\n",
    "    header = rows[0]\n",
    "    num_columns = len(header)\n",
    "    indices_to_remove = [i for i, h in enumerate(header) if h.lower() in ['-date', '-time'] or all((len(row) > i and row[i] == '') for row in rows[1:])]\n",
    "\n",
    "    # Remove the specified columns from the header and rows\n",
    "    updated_header = [h for i, h in enumerate(header) if i not in indices_to_remove]\n",
    "    updated_rows = [[item for i, item in enumerate(row[:num_columns]) if i not in indices_to_remove] for row in rows[1:]]\n",
    "\n",
    "    # Write the updated data to the output file\n",
    "    with open(output_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(updated_header)  # Write the updated header\n",
    "        writer.writerows(updated_rows)  # Write the updated data rows\n",
    "\n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef704a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200s\n",
      "2000s\n"
     ]
    }
   ],
   "source": [
    "for i in [200,2000]:\n",
    "    exp_ls = f'{i}s'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-memory_new.csv'\n",
    "    output_file_path =f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\pcm-memory_new.csv'\n",
    "    remove_columns_and_empty_values(input_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee86f50",
   "metadata": {},
   "source": [
    "# extract traffic and latency information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84bc9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def latency_pre(input_csv, output_csv, delimiter=' '):\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_csv, delimiter=delimiter, header=None)\n",
    "    df.drop(columns=df.columns[0], inplace=True)\n",
    "    df.to_csv(output_csv, index=False, header=False, sep=delimiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d32bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200s\n",
      "2000s\n"
     ]
    }
   ],
   "source": [
    "for i in [200,2000]:\n",
    "    exp_ls = f'{i}s'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\latency.csv'\n",
    "    output_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\latency_new.csv'\n",
    "    latency_pre(input_file_path, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "450c345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000s\n"
     ]
    }
   ],
   "source": [
    "print(exp_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b219f",
   "metadata": {},
   "source": [
    "# add header for nf_out csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7216d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def add_header_to_csv(input_file_path, output_file_path, header):\n",
    "    with open(input_file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        data = list(reader)\n",
    "        \n",
    "    with open(output_file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5297094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200s\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n",
      "2000s\n",
      "['tag', 'instance_id', 'service_id', 'thread_info.core', 'rx_pps', 'tx_pps', 'rx', 'tx', 'act_out', 'act_tonf', 'act_drop', 'thread_info.parent', 'state', 'rte_atomic16_read(thread_info.children_cnt)', 'rx_drop_rate', 'tx_drop_rate', 'rx_drop', 'tx_drop', 'act_next', 'act_buffer', 'act_returned']\n"
     ]
    }
   ],
   "source": [
    "for i in [200,2000]:\n",
    "    exp_ls = f'{i}s'\n",
    "    print(exp_ls)\n",
    "    input_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\nf_out.csv'\n",
    "    output_file_path = f'..\\\\ndpi-stats-random\\\\{exp_ls}\\\\nf_out_new.csv'\n",
    "\n",
    "    header = [\"tag\", \"instance_id\", \"service_id\", \"thread_info.core\",\n",
    "              \"rx_pps\",\"tx_pps\", \"rx\", \"tx\", \"act_out\", \"act_tonf\",\"act_drop\", \"thread_info.parent\",\n",
    "              \"state\", \"rte_atomic16_read(thread_info.children_cnt)\", \n",
    "             \"rx_drop_rate\",\"tx_drop_rate\", \"rx_drop\",\"tx_drop\", \"act_next\", \n",
    "             \"act_buffer\",\"act_returned\"]\n",
    "    print(header)\n",
    "    add_header_to_csv( input_file_path, output_file_path, header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d52f06",
   "metadata": {},
   "source": [
    "# ddioway transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "beb1fd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to ..\\ndpi-stats-random\\2000s\\ddio_ways_new.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def convert_hex_to_binary_and_count_ones(input_csv_file, output_csv_file):\n",
    "    df = pd.read_csv(input_csv_file)\n",
    "    \n",
    "\n",
    "    column_name = df.columns[0] \n",
    "    \n",
    "\n",
    "    df['binary'] = df[column_name].apply(lambda x: bin(int(x, 16))[2:] if pd.notnull(x) else x)\n",
    "    df['ddio_ways'] = df['binary'].apply(lambda x: x.count('1') if isinstance(x, str) else 0)\n",
    "\n",
    "    df.columns.values[0] = \"cos_way\"\n",
    "    df.to_csv(output_csv_file, index=False)\n",
    "    print(f\"Processed data saved to {output_csv_file}\")\n",
    "\n",
    "input_csv_file = '..\\\\ndpi-stats-random\\\\2000s\\\\ddio_ways.csv'\n",
    "output_csv_file = '..\\\\ndpi-stats-random\\\\2000s\\\\ddio_ways_new.csv'\n",
    "convert_hex_to_binary_and_count_ones(input_csv_file, output_csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c6b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
